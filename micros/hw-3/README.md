# Домашнее задание к занятию «Микросервисы: подходы»

_Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры._
_Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации._


## Задача 1: Обеспечить разработку

_Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка._  
_Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия._

_Решение должно соответствовать следующим требованиям:_
_- облачная система;_  
_- система контроля версий Git;_  
_- репозиторий на каждый сервис;_  
_- запуск сборки по событию из системы контроля версий;_  
_- запуск сборки по кнопке с указанием параметров;_  
_- возможность привязать настройки к каждой сборке;_  
_- возможность создания шаблонов для различных конфигураций сборок;_  
_- возможность безопасного хранения секретных данных (пароли, ключи доступа);_  
_- несколько конфигураций для сборки из одного репозитория;_  
_- кастомные шаги при сборке;_  
_- собственные докер-образы для сборки проектов;_  
_- возможность развернуть агентов сборки на собственных серверах;_  
_- возможность параллельного запуска нескольких сборок;_  
_- возможность параллельного запуска тестов._  

_Обоснуйте свой выбор._
  
Если кратко, то __Gitlab + SonarCube + Sonatype Nexus__. Gitlab обладает всеми перечисленными требованиями. Имеет встроенную систему контроля версий Git, можно делить репозитории по namespace, проектам, как удобно. Есть облачная версия. Есть возможность использования своих gitlab-runner. Есть встроенный docker-registry, но я бы предпочел Sonatype Nexus, так как он поддерживает хранение не только докер-образов, а так же множества проприетарных форматов артефактов, таких как python, go, npm и многие другие. Так же Nexus может выступать в роли proxy для хранения пакетов, что очень удобно. Ну а для валидации кода - SonarCube.

Как альтернативное решение можно рассмотреть __GitHub + Hashicorp Vault + Sonatype Nexus + SonarCube__ или __TeamCity__, но по набору фич эти системы более скудные и менее удобные, чем Gitlab. GitHub Actions лично мне не зашел, я не могу сказать, что Gitlab CI более интуитивный, но мне понравился больше. А с TeamCity я почти не работал, разве что в рамках этого курса.
  
## Задача 2: Логи

_Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре._  
_Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия._  

_Решение должно соответствовать следующим требованиям:_  
_- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;_  
_- минимальные требования к приложениям, сбор логов из stdout;_  
_- гарантированная доставка логов до центрального хранилища;_  
_- обеспечение поиска и фильтрации по записям логов;_  
_- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;_  
_- возможность дать ссылку на сохранённый поиск по записям логов._  

_Обоснуйте свой выбор._
  
Первое, что приходит на ум __Elasticsearch + Logstash + Kibana__ он же ELK, это довольно распространенное решение. Но требует значительных ресурсов, так же данный стэк довольно сложен в настройке, так же некоторые фичи платные. Как альтернативу можно предложить __Graylog__, он менее требователен и быстрее развертывается, но сложнее масштабируется.
  
- **ELK + Fluent Bit/Filebeat**:
  - Подходит для систем, где критична надежная доставка логов и требуется высокая масштабируемость.
  - Предпочтителен для крупных и распределенных систем с высоким объемом логов.
  - Требует больше усилий для развертывания и управления.

- **Graylog**:
  - Отличный выбор для систем, где важны простота развертывания и управления.
  - Подходит для малых и средних систем, где нет высоких требований к гарантированной доставке логов.
  - Может использоваться с брокерами сообщений (например, Kafka) для повышения надежности доставки логов.

Обе системы предлагают мощные инструменты для работы с логами и могут быть адаптированы под различные сценарии использования, что позволяет выбирать наиболее подходящее решение в зависимости от конкретных условий и требований.
  
## Задача 3: Мониторинг

_Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре._  
_Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия._  

_Решение должно соответствовать следующим требованиям:_  
_- сбор метрик со всех хостов, обслуживающих систему;_  
_- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;_  
_- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;_  
_- сбор метрик, специфичных для каждого сервиса;_  
_- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;_  
_- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы._  

_Обоснуйте свой выбор._  

1. **Prometheus**:
   - **Сбор и хранение метрик**: Prometheus является мощной системой мониторинга, которая собирает метрики с различных источников и хранит их в своей временной базе данных.
   - **Pull-модель**: Prometheus использует pull-модель для сбора метрик, что упрощает интеграцию и управление мониторингом.
   - **Alertmanager**: Встроенная поддержка системы оповещений позволяет настроить уведомления на основе различных условий.

2. **Node Exporter**:
   - **Состояние ресурсов хостов**: Node Exporter собирает метрики состояния ресурсов хостов, такие как CPU, RAM, HDD, Network, и предоставляет их в формате, который может быть легко собран Prometheus.
   - **Легкость установки**: Устанавливается на каждом хосте и автоматически собирает необходимые метрики.

3. **Grafana**:
   - **Визуализация**: Grafana предоставляет мощные инструменты для визуализации метрик, собранных Prometheus.
   - **Настройка панелей**: Пользовательский интерфейс Grafana позволяет настраивать различные панели для отслеживания состояния системы, создавать запросы и агрегировать информацию.
   - **Удобство использования**: Поддержка различных источников данных и возможность создания кастомных дашбордов делает Grafana отличным выбором для визуализации и анализа метрик.

**Принципы взаимодействия:**

1. **Сбор метрик с хостов**: 
   - **Node Exporter** устанавливается на каждом хосте и собирает метрики состояния ресурсов (CPU, RAM, HDD, Network).

2. **Сбор и хранение метрик**:
   - **Prometheus** периодически опрашивает Node Exporter, cAdvisor и Custom Exporters, собирая метрики и сохраняя их в своей базе данных.

3. **Визуализация и анализ**:
   - **Grafana** подключается к Prometheus и предоставляет интерфейс для визуализации и анализа метрик. Пользователи могут создавать и настраивать дашборды, устанавливать оповещения и выполнять запросы для получения агрегированной информации о состоянии системы.

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---